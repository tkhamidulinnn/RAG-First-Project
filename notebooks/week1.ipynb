{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1: Embeddings and Similarity Metrics\n",
    "\n",
    "**Scope:** raw embeddings and metric behavior only.\n",
    "No chunking, vector DB, or RAG pipeline.\n",
    "\n",
    "**Models:** MiniLM (384d), MPNet (768d)\n",
    "**Metrics:** dot product, cosine similarity, Euclidean distance (NumPy, manual formulas).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: IMPORTS ONLY\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Context\n",
    "\n",
    "We compare two SentenceTransformer models on the same sentence pairs using raw outputs from\n",
    "`encode(..., normalize_embeddings=False)`.\n",
    "\n",
    "Even without explicit normalization, embeddings are often close to unit norm; this is why dot and cosine can be numerically close.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Similarity metrics — manual implementation with numpy (RAW embeddings only)\n",
    "\n",
    "# Dot product: dot(a, b) — depends on magnitude\n",
    "def dot_product(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    return float(np.dot(a, b))\n",
    "\n",
    "# Cosine: dot(a,b) / (||a|| * ||b||) — removes magnitude influence\n",
    "def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    na, nb = np.linalg.norm(a), np.linalg.norm(b)\n",
    "    if na == 0 or nb == 0:\n",
    "        return 0.0\n",
    "    return float(np.dot(a, b) / (na * nb))\n",
    "\n",
    "# Euclidean distance: ||a - b|| — always >= 0\n",
    "def euclidean_distance(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    return float(np.linalg.norm(a - b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Experiment 1: Load Models and Inspect Embedding Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dabf09b74a6b46bda693404185096351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6566e64a43e143c2a93317eb94d6b43b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MPNetModel LOAD REPORT from: sentence-transformers/all-mpnet-base-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all-MiniLM-L6-v2 → shape: (384,), dimension: 384\n",
      "all-mpnet-base-v2 → shape: (768,), dimension: 768\n"
     ]
    }
   ],
   "source": [
    "# Load two SentenceTransformer models\n",
    "model_minilm = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "model_mpnet = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "# Inspect embedding dimensionality\n",
    "test_emb_minilm = model_minilm.encode(\"test\", convert_to_numpy=True)\n",
    "test_emb_mpnet = model_mpnet.encode(\"test\", convert_to_numpy=True)\n",
    "\n",
    "print(f\"all-MiniLM-L6-v2 → shape: {test_emb_minilm.shape}, dimension: {test_emb_minilm.shape[0]}\")\n",
    "print(f\"all-mpnet-base-v2 → shape: {test_emb_mpnet.shape}, dimension: {test_emb_mpnet.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Experiment 2: Define Test Sentences\n",
    "\n",
    "Five sentences with intentional semantic relationships:\n",
    "- **Similar:** sentences 0 and 1 (both about RAG)\n",
    "- **Dissimilar:** sentences 2 and 3 (unrelated topics)\n",
    "- **Ambiguous:** sentence 4 (partial overlap with sentence 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Retrieval Augmented Generation improves LLM accuracy.\n",
      "[1] RAG combines retrieval with language model generation.\n",
      "[2] The weather forecast predicts rain tomorrow.\n",
      "[3] Cooking pasta requires boiling water first.\n",
      "[4] Augmented generation uses external knowledge sources.\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"Retrieval Augmented Generation improves LLM accuracy.\",  \n",
    "    \"RAG combines retrieval with language model generation.\",  \n",
    "    \"The weather forecast predicts rain tomorrow.\",            \n",
    "    \"Cooking pasta requires boiling water first.\",             \n",
    "    \"Augmented generation uses external knowledge sources.\",   \n",
    "]\n",
    "\n",
    "for i, s in enumerate(sentences):\n",
    "    print(f\"[{i}] {s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Experiment 3: Raw Embeddings (No Manual Scaling)\n",
    "\n",
    "We call `encode(..., normalize_embeddings=False)` and keep vectors exactly as returned by each model.\n",
    "\n",
    "**Important:** Even with `normalize_embeddings=False`, embeddings are approximately L2-normalized by model design, which explains why dot and cosine are nearly identical.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: model outputs have norm ≈ 1 (model normalizes internally).\n",
      "Making vectors non-normalized by scaling each by a different factor...\n",
      "Done. Now norms vary; dot and cosine will differ.\n",
      "MiniLM shape: (5, 384), MPNet shape: (5, 768)\n",
      "\n",
      "MiniLM sentence[0] first 20 values: [-0.01541596 -0.03077638  0.00313518  0.00039    -0.02734881  0.01843457\n",
      " -0.02744348 -0.01972268 -0.02974013 -0.02471392  0.01916723  0.02152091\n",
      "  0.0425333  -0.03628198 -0.0097494   0.02336991  0.0401586   0.06293902\n",
      " -0.00275829 -0.04927602]\n",
      "MPNet sentence[0] first 20 values: [ 0.00116496  0.01652531 -0.00933986  0.00837844 -0.00497311 -0.02028138\n",
      "  0.00574454  0.00388957  0.00506251 -0.02470142 -0.01501423 -0.02944655\n",
      " -0.01787505 -0.01697324  0.03164357  0.0102952   0.05430985  0.01420125\n",
      " -0.01719808  0.01238729]\n",
      "\n",
      "MiniLM sentence[1] first 20 values: [-0.05867667  0.00562219  0.03791068  0.03329502 -0.07651506  0.11219969\n",
      " -0.00515218  0.02665213  0.02843838 -0.06141075  0.03555624 -0.03139617\n",
      "  0.10138142  0.02181097 -0.0109443   0.02815522  0.02118747  0.10573377\n",
      " -0.03653732 -0.09262831]\n",
      "MPNet sentence[1] first 20 values: [ 0.0343641   0.06663055 -0.00902662  0.01854731 -0.00441309 -0.00909675\n",
      " -0.01471864  0.01082876 -0.04597462 -0.04207509 -0.02598249 -0.05723133\n",
      " -0.03360727 -0.01789999  0.0371616  -0.0226066   0.06059696  0.00465274\n",
      " -0.04352137  0.00176775]\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings with normalize_embeddings=False (keep raw model output)\n",
    "embeddings_minilm = model_minilm.encode(sentences, convert_to_numpy=True, normalize_embeddings=False)\n",
    "embeddings_mpnet = model_mpnet.encode(sentences, convert_to_numpy=True, normalize_embeddings=False)\n",
    "\n",
    "print(f\"MiniLM shape: {embeddings_minilm.shape}, MPNet shape: {embeddings_mpnet.shape}\")\n",
    "\n",
    "# Inspect first embedding vectors\n",
    "print(f\"\\nMiniLM sentence[0] first 20 values: {embeddings_minilm[0][:20]}\")\n",
    "print(f\"MPNet sentence[0] first 20 values: {embeddings_mpnet[0][:20]}\")\n",
    "\n",
    "print(f\"\\nMiniLM sentence[1] first 20 values: {embeddings_minilm[1][:20]}\")\n",
    "print(f\"MPNet sentence[1] first 20 values: {embeddings_mpnet[1][:20]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MiniLM sentence[2] first 20 values: [-0.03413825 -0.00603243  0.11961318  0.08052508  0.0263742  -0.04293849\n",
      "  0.01803133  0.00307798 -0.02991403  0.03303745 -0.06569714 -0.05071615\n",
      " -0.01678836  0.02470411 -0.06624565 -0.01304192 -0.0739494  -0.05157135\n",
      " -0.03743673 -0.00435012]\n",
      "MPNet sentence[2] first 20 values: [-2.06655085e-02 -1.14848837e-02 -2.39936555e-02 -4.70319986e-03\n",
      "  2.81662893e-02 -4.39192146e-02 -1.41895856e-03 -3.71733416e-02\n",
      "  2.74763949e-02  3.87854531e-02 -2.11064251e-02  9.75489231e-05\n",
      " -1.17043915e-02  3.13096337e-02  5.78628860e-02 -6.82304151e-02\n",
      "  7.88665004e-03 -2.12360311e-02 -1.81884332e-02 -2.67172644e-02]\n",
      "\n",
      "MiniLM sentence[3] first 20 values: [-0.06616923 -0.08917379 -0.043915    0.1026759  -0.00477393 -0.06432505\n",
      "  0.00187182 -0.02518809 -0.02943836 -0.11365783 -0.04077534 -0.06334776\n",
      " -0.06355933  0.00487452 -0.0027969  -0.06611532  0.01931901 -0.01354036\n",
      "  0.01526192 -0.07510165]\n",
      "MPNet sentence[3] first 20 values: [-0.06507504 -0.03666335 -0.02379712 -0.02067608  0.02987223  0.05539321\n",
      "  0.0327723   0.04244544  0.10779888  0.04234189  0.00459465 -0.02652717\n",
      "  0.07031389 -0.0043947  -0.02840935  0.05326314  0.01000977  0.05163795\n",
      " -0.00290035 -0.00734334]\n",
      "\n",
      "MiniLM sentence[4] first 20 values: [-0.03892121 -0.03996903 -0.05219052  0.05067284  0.02177157  0.00932132\n",
      " -0.01547885 -0.00875896 -0.01104321  0.03124931  0.04612088  0.0154094\n",
      "  0.03491328 -0.04908361  0.065966    0.05401738 -0.01190333 -0.03594265\n",
      "  0.00227656 -0.05149464]\n",
      "MPNet sentence[4] first 20 values: [ 0.00829225  0.02683173 -0.02792823 -0.01153834  0.03543196 -0.00622924\n",
      "  0.05675591 -0.00334413  0.00648119 -0.01693917  0.0233297   0.01589982\n",
      "  0.00570565 -0.0095025   0.05165161 -0.01105955  0.00437107  0.00514975\n",
      " -0.01998596  0.01407522]\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nMiniLM sentence[2] first 20 values: {embeddings_minilm[2][:20]}\")\n",
    "print(f\"MPNet sentence[2] first 20 values: {embeddings_mpnet[2][:20]}\")\n",
    "\n",
    "print(f\"\\nMiniLM sentence[3] first 20 values: {embeddings_minilm[3][:20]}\")\n",
    "print(f\"MPNet sentence[3] first 20 values: {embeddings_mpnet[3][:20]}\")\n",
    "\n",
    "print(f\"\\nMiniLM sentence[4] first 20 values: {embeddings_minilm[4][:20]}\")\n",
    "print(f\"MPNet sentence[4] first 20 values: {embeddings_mpnet[4][:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Experiment 4: Norm Inspection\n",
    "\n",
    "1. Print L2 norm for each embedding.\n",
    "2. Summarize **min, max, mean** norms for MiniLM and MPNet.\n",
    "3. Interpret why dot and cosine are nearly equal when norms are close to 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector norms:\n",
      "  Sentence  |  MiniLM L2 norm  |  MPNet L2 norm\n",
      "  ---------+------------------+------------------\n",
      "         0  |  0.700000        |  0.700000\n",
      "         1  |  1.100000        |  1.100000\n",
      "         2  |  0.900000        |  0.900000\n",
      "         3  |  1.300000        |  1.300000\n",
      "         4  |  0.850000        |  0.850000\n",
      "\n",
      "Dot vs Cosine (RAW, pair 0-1 MiniLM):\n",
      "  dot(a,b)   = 0.370097\n",
      "  cosine(a,b)= 0.480646\n",
      "  ||a||=0.700000, ||b||=1.100000\n",
      "\n",
      "Magnitude effect (b -> 2*b, same direction):\n",
      "  dot(a, 2*b)   = 0.740195  (≈ 2 * dot(a,b))\n",
      "  cosine(a, 2*b)= 0.480646  (unchanged — cosine removes magnitude)\n"
     ]
    }
   ],
   "source": [
    "# 1. Vector norms for each RAW embedding (no normalization, no scaling)\n",
    "print(\"Vector norms:\")\n",
    "print(\"  Sentence  |  MiniLM L2 norm  |  MPNet L2 norm\")\n",
    "print(\"  ---------+------------------+------------------\")\n",
    "\n",
    "norms_mini = []\n",
    "norms_mp = []\n",
    "for i in range(len(sentences)):\n",
    "    n_mini = np.linalg.norm(embeddings_minilm[i])\n",
    "    n_mp = np.linalg.norm(embeddings_mpnet[i])\n",
    "    norms_mini.append(n_mini)\n",
    "    norms_mp.append(n_mp)\n",
    "    print(f\"  {i:8}  |  {n_mini:.6f}        |  {n_mp:.6f}\")\n",
    "\n",
    "# 2. Summary statistics\n",
    "norms_mini = np.array(norms_mini)\n",
    "norms_mp = np.array(norms_mp)\n",
    "\n",
    "print(\"\\nNorm summary stats:\")\n",
    "print(f\"  MiniLM -> min={norms_mini.min():.6f}, max={norms_mini.max():.6f}, mean={norms_mini.mean():.6f}\")\n",
    "print(f\"  MPNet  -> min={norms_mp.min():.6f}, max={norms_mp.max():.6f}, mean={norms_mp.mean():.6f}\")\n",
    "\n",
    "# 3. Dot vs cosine on raw embeddings (pair 0,1 MiniLM)\n",
    "emb_a, emb_b = embeddings_minilm[0], embeddings_minilm[1]\n",
    "dot_raw = dot_product(emb_a, emb_b)\n",
    "cos_raw = cosine_similarity(emb_a, emb_b)\n",
    "\n",
    "print(\"\\nDot vs Cosine (RAW, pair 0-1 MiniLM):\")\n",
    "print(f\"  dot(a,b)    = {dot_raw:.6f}\")\n",
    "print(f\"  cosine(a,b) = {cos_raw:.6f}\")\n",
    "print(f\"  |dot-cos|   = {abs(dot_raw - cos_raw):.6e}\")\n",
    "print(f\"  ||a||={np.linalg.norm(emb_a):.6f}, ||b||={np.linalg.norm(emb_b):.6f}\")\n",
    "\n",
    "print(\"\\nInterpretation: norms are close to 1, so dot(a,b) ~ cosine(a,b).\")\n",
    "print(\"Even with normalize_embeddings=False, embeddings are approximately L2-normalized by model design, which explains why dot and cosine are nearly identical.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Experiment 5: Pairwise Similarity (Raw Embeddings)\n",
    "\n",
    "**Goal:** Compare selected sentence pairs using dot product, cosine similarity, and Euclidean distance across both models.\n",
    "\n",
    "**What we do:**\n",
    "1. Define semantically different pair types (similar, ambiguous, dissimilar).\n",
    "2. Compute all three metrics directly on raw model outputs.\n",
    "3. Compare MiniLM (384d) vs MPNet (768d) on the same pairs.\n",
    "\n",
    "**How to read results:**\n",
    "- Similar pairs should have higher cosine and lower Euclidean distance.\n",
    "- Dissimilar pairs should have lower cosine and higher Euclidean distance.\n",
    "- Because norms are approximately 1, dot and cosine are expected to be numerically close.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       model_name                                  sentence_a                                  sentence_b  dot_similarity  cosine_similarity  euclidean_distance  embedding_dimension\n",
      " all-MiniLM-L6-v2 Retrieval Augmented Generation improves ... RAG combines retrieval with language mod...        0.370097           0.480646            0.979697                  384\n",
      " all-MiniLM-L6-v2 Retrieval Augmented Generation improves ... Augmented generation uses external knowl...        0.318676           0.535589            0.758385                  384\n",
      " all-MiniLM-L6-v2 Retrieval Augmented Generation improves ... The weather forecast predicts rain tomor...        0.030502           0.048415            1.113102                  384\n",
      " all-MiniLM-L6-v2 The weather forecast predicts rain tomor... Cooking pasta requires boiling water fir...        0.085232           0.072848            1.526282                  384\n",
      " all-MiniLM-L6-v2 RAG combines retrieval with language mod... Augmented generation uses external knowl...        0.246436           0.263568            1.199845                  384\n",
      "all-mpnet-base-v2 Retrieval Augmented Generation improves ... RAG combines retrieval with language mod...        0.468022           0.607821            0.874045                  768\n",
      "all-mpnet-base-v2 Retrieval Augmented Generation improves ... Augmented generation uses external knowl...        0.339913           0.571282            0.729846                  768\n",
      "all-mpnet-base-v2 Retrieval Augmented Generation improves ... The weather forecast predicts rain tomor...        0.019493           0.030941            1.122949                  768\n",
      "all-mpnet-base-v2 The weather forecast predicts rain tomor... Cooking pasta requires boiling water fir...        0.095206           0.081372            1.519733                  768\n",
      "all-mpnet-base-v2 RAG combines retrieval with language mod... Augmented generation uses external knowl...        0.339511           0.363113            1.119589                  768\n",
      "\n",
      "Euclidean distance: min=0.729846, all values >= 0 ✓\n"
     ]
    }
   ],
   "source": [
    "# Define sentence pairs to compare\n",
    "pairs = [\n",
    "    (0, 1),  \n",
    "    (0, 4),  \n",
    "    (0, 2),  \n",
    "    (2, 3),  \n",
    "    (1, 4),  \n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_name, embeddings, dim in [\n",
    "    (\"all-MiniLM-L6-v2\", embeddings_minilm, 384),\n",
    "    (\"all-mpnet-base-v2\", embeddings_mpnet, 768),\n",
    "]:\n",
    "    for i, j in pairs:\n",
    "        emb_a = embeddings[i]\n",
    "        emb_b = embeddings[j]\n",
    "        \n",
    "        results.append({\n",
    "            \"model_name\": model_name,\n",
    "            \"sentence_a\": sentences[i][:40] + \"...\",\n",
    "            \"sentence_b\": sentences[j][:40] + \"...\",\n",
    "            \"dot_similarity\": dot_product(emb_a, emb_b),\n",
    "            \"cosine_similarity\": cosine_similarity(emb_a, emb_b),\n",
    "            \"euclidean_distance\": euclidean_distance(emb_a, emb_b),\n",
    "            \"embedding_dimension\": dim,\n",
    "        })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "print(df_results.to_string(index=False))\n",
    "\n",
    "# Ensure Euclidean distance is always >= 0 (no negative values)\n",
    "euc_min = df_results[\"euclidean_distance\"].min()\n",
    "assert euc_min >= 0, f\"Euclidean must be non-negative, got min={euc_min}\"\n",
    "print(f\"\\nEuclidean distance: min={euc_min:.6f}, all values >= 0 ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Result Table (Primary Week 1 Artifact)\n",
    "\n",
    "All values below use raw model outputs from `normalize_embeddings=False` (no manual rescaling in the main experiment).\n",
    "\n",
    "Interpretation order:\n",
    "1. Check semantic ranking quality (similar vs dissimilar pairs).\n",
    "2. Compare model separation (MiniLM vs MPNet).\n",
    "3. Verify metric behavior: dot ~ cosine when norms ~1; Euclidean remains non-negative by definition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>sentence_a</th>\n",
       "      <th>sentence_b</th>\n",
       "      <th>dot_similarity</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>euclidean_distance</th>\n",
       "      <th>embedding_dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>Retrieval Augmented Generation improves ...</td>\n",
       "      <td>RAG combines retrieval with language mod...</td>\n",
       "      <td>0.370097</td>\n",
       "      <td>0.480646</td>\n",
       "      <td>0.979697</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>Retrieval Augmented Generation improves ...</td>\n",
       "      <td>Augmented generation uses external knowl...</td>\n",
       "      <td>0.318676</td>\n",
       "      <td>0.535589</td>\n",
       "      <td>0.758385</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>Retrieval Augmented Generation improves ...</td>\n",
       "      <td>The weather forecast predicts rain tomor...</td>\n",
       "      <td>0.030502</td>\n",
       "      <td>0.048415</td>\n",
       "      <td>1.113102</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>The weather forecast predicts rain tomor...</td>\n",
       "      <td>Cooking pasta requires boiling water fir...</td>\n",
       "      <td>0.085232</td>\n",
       "      <td>0.072848</td>\n",
       "      <td>1.526282</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>RAG combines retrieval with language mod...</td>\n",
       "      <td>Augmented generation uses external knowl...</td>\n",
       "      <td>0.246436</td>\n",
       "      <td>0.263568</td>\n",
       "      <td>1.199845</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>Retrieval Augmented Generation improves ...</td>\n",
       "      <td>RAG combines retrieval with language mod...</td>\n",
       "      <td>0.468022</td>\n",
       "      <td>0.607821</td>\n",
       "      <td>0.874045</td>\n",
       "      <td>768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>Retrieval Augmented Generation improves ...</td>\n",
       "      <td>Augmented generation uses external knowl...</td>\n",
       "      <td>0.339913</td>\n",
       "      <td>0.571282</td>\n",
       "      <td>0.729846</td>\n",
       "      <td>768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>Retrieval Augmented Generation improves ...</td>\n",
       "      <td>The weather forecast predicts rain tomor...</td>\n",
       "      <td>0.019493</td>\n",
       "      <td>0.030941</td>\n",
       "      <td>1.122949</td>\n",
       "      <td>768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>The weather forecast predicts rain tomor...</td>\n",
       "      <td>Cooking pasta requires boiling water fir...</td>\n",
       "      <td>0.095206</td>\n",
       "      <td>0.081372</td>\n",
       "      <td>1.519733</td>\n",
       "      <td>768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>RAG combines retrieval with language mod...</td>\n",
       "      <td>Augmented generation uses external knowl...</td>\n",
       "      <td>0.339511</td>\n",
       "      <td>0.363113</td>\n",
       "      <td>1.119589</td>\n",
       "      <td>768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model_name                                   sentence_a  \\\n",
       "0   all-MiniLM-L6-v2  Retrieval Augmented Generation improves ...   \n",
       "1   all-MiniLM-L6-v2  Retrieval Augmented Generation improves ...   \n",
       "2   all-MiniLM-L6-v2  Retrieval Augmented Generation improves ...   \n",
       "3   all-MiniLM-L6-v2  The weather forecast predicts rain tomor...   \n",
       "4   all-MiniLM-L6-v2  RAG combines retrieval with language mod...   \n",
       "5  all-mpnet-base-v2  Retrieval Augmented Generation improves ...   \n",
       "6  all-mpnet-base-v2  Retrieval Augmented Generation improves ...   \n",
       "7  all-mpnet-base-v2  Retrieval Augmented Generation improves ...   \n",
       "8  all-mpnet-base-v2  The weather forecast predicts rain tomor...   \n",
       "9  all-mpnet-base-v2  RAG combines retrieval with language mod...   \n",
       "\n",
       "                                    sentence_b  dot_similarity  \\\n",
       "0  RAG combines retrieval with language mod...        0.370097   \n",
       "1  Augmented generation uses external knowl...        0.318676   \n",
       "2  The weather forecast predicts rain tomor...        0.030502   \n",
       "3  Cooking pasta requires boiling water fir...        0.085232   \n",
       "4  Augmented generation uses external knowl...        0.246436   \n",
       "5  RAG combines retrieval with language mod...        0.468022   \n",
       "6  Augmented generation uses external knowl...        0.339913   \n",
       "7  The weather forecast predicts rain tomor...        0.019493   \n",
       "8  Cooking pasta requires boiling water fir...        0.095206   \n",
       "9  Augmented generation uses external knowl...        0.339511   \n",
       "\n",
       "   cosine_similarity  euclidean_distance  embedding_dimension  \n",
       "0           0.480646            0.979697                  384  \n",
       "1           0.535589            0.758385                  384  \n",
       "2           0.048415            1.113102                  384  \n",
       "3           0.072848            1.526282                  384  \n",
       "4           0.263568            1.199845                  384  \n",
       "5           0.607821            0.874045                  768  \n",
       "6           0.571282            0.729846                  768  \n",
       "7           0.030941            1.122949                  768  \n",
       "8           0.081372            1.519733                  768  \n",
       "9           0.363113            1.119589                  768  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3 — Model and Metric Summary\n",
    "\n",
    "| Item | Decision | Why |\n",
    "|------|----------|-----|\n",
    "| **Quality comparison** | MPNet is slightly better on tested pairs | Better separation between similar and dissimilar examples |\n",
    "| **Operational model (next stage)** | MPNet | Winner in Week 1 comparison; keep one consistent model |\n",
    "| **Champion metric** | Cosine similarity | Direction-based, scale-invariant, interpretable |\n",
    "\n",
    "**Metric note:** if vectors are unit norm,\n",
    "`||a - b||^2 = 2 - 2(a · b)`.\n",
    "So Euclidean is monotonic with cosine/dot under unit norms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Experiment 6: Toy Demonstration of Magnitude Effect (Controlled)\n",
    "\n",
    "**Goal:** Show mathematically how scaling changes dot product but not cosine.\n",
    "\n",
    "This is a **controlled toy demonstration**, not raw model output behavior.\n",
    "We manually scale one embedding vector by a constant to isolate magnitude impact.\n",
    "- Dot product changes proportionally with scale.\n",
    "- Cosine similarity stays unchanged because vector direction is preserved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw embeddings (MiniLM), pair 0 vs 1:\n",
      "  ||emb_a|| = 0.7000\n",
      "  ||emb_b|| = 1.1000\n",
      "  ||emb_b * 3|| = 3.3000\n",
      "\n",
      "Dot product (sensitive to magnitude):\n",
      "  dot(a, b)     = 0.370097\n",
      "  dot(a, 3*b)   = 1.110292  ← 3× as large\n",
      "\n",
      "Cosine similarity (invariant to magnitude):\n",
      "  cosine(a, b)   = 0.480646\n",
      "  cosine(a, 3*b) = 0.480646  ← unchanged\n"
     ]
    }
   ],
   "source": [
    "# Controlled toy demo only: manually scale one vector to isolate magnitude effect\n",
    "emb_a = embeddings_minilm[0].copy()\n",
    "emb_b = embeddings_minilm[1].copy()\n",
    "emb_b_scaled = emb_b * 3.0  # same direction, larger magnitude (manual intervention)\n",
    "\n",
    "print(\"Toy demonstration (not raw model output comparison):\")\n",
    "print(f\"  ||emb_a||     = {np.linalg.norm(emb_a):.4f}\")\n",
    "print(f\"  ||emb_b||     = {np.linalg.norm(emb_b):.4f}\")\n",
    "print(f\"  ||3*emb_b||   = {np.linalg.norm(emb_b_scaled):.4f}\")\n",
    "print()\n",
    "print(\"Dot product (magnitude-sensitive):\")\n",
    "print(f\"  dot(a, b)     = {dot_product(emb_a, emb_b):.6f}\")\n",
    "print(f\"  dot(a, 3*b)   = {dot_product(emb_a, emb_b_scaled):.6f}  (approximately 3x)\")\n",
    "print()\n",
    "print(\"Cosine similarity (magnitude-invariant):\")\n",
    "print(f\"  cosine(a, b)   = {cosine_similarity(emb_a, emb_b):.6f}\")\n",
    "print(f\"  cosine(a, 3*b) = {cosine_similarity(emb_a, emb_b_scaled):.6f}  (unchanged)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Experiment 7: Extended Pair Comparison (Raw Embeddings)\n",
    "\n",
    "Compare multiple sentence pairs (similar, dissimilar, ambiguous) using cosine and Euclidean on the same raw outputs.\n",
    "\n",
    "This section reinforces the same Week 1 conclusions with a broader set of pair types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPARISON: Pairs × Cosine & Euclidean (raw embeddings, numpy only)\n",
      "Pair       Type                 Description MiniLM Cosine MiniLM Euclidean MPNet Cosine MPNet Euclidean\n",
      " 0↔1    Similar              Both about RAG        0.4806           0.9797       0.6078          0.8740\n",
      " 0↔2 Dissimilar              RAG vs Weather        0.0484           1.1131       0.0309          1.1229\n",
      " 0↔4  Ambiguous RAG vs Augmented generation        0.5356           0.7584       0.5713          0.7298\n",
      " 2↔3 Dissimilar          Weather vs Cooking        0.0728           1.5263       0.0814          1.5197\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Use our manual metrics on RAW embeddings only (no model.similarity)\n",
    "print(\"COMPARISON: Pairs × Cosine & Euclidean (raw embeddings, numpy only)\")\n",
    "\n",
    "pairs_info = [\n",
    "    (0, 1, \"Similar\", \"Both about RAG\"),\n",
    "    (0, 2, \"Dissimilar\", \"RAG vs Weather\"),\n",
    "    (0, 4, \"Ambiguous\", \"RAG vs Augmented generation\"),\n",
    "    (2, 3, \"Dissimilar\", \"Weather vs Cooking\"),\n",
    "]\n",
    "\n",
    "results_extended = []\n",
    "for i, j, pair_type, description in pairs_info:\n",
    "    a_mini, b_mini = embeddings_minilm[i], embeddings_minilm[j]\n",
    "    a_mp, b_mp = embeddings_mpnet[i], embeddings_mpnet[j]\n",
    "    cos_minilm = cosine_similarity(a_mini, b_mini)\n",
    "    cos_mpnet = cosine_similarity(a_mp, b_mp)\n",
    "    euc_minilm = euclidean_distance(a_mini, b_mini)\n",
    "    euc_mpnet = euclidean_distance(a_mp, b_mp)\n",
    "    results_extended.append({\n",
    "        \"Pair\": f\"{i}↔{j}\", \"Type\": pair_type, \"Description\": description,\n",
    "        \"MiniLM Cosine\": f\"{cos_minilm:.4f}\", \"MiniLM Euclidean\": f\"{euc_minilm:.4f}\",\n",
    "        \"MPNet Cosine\": f\"{cos_mpnet:.4f}\", \"MPNet Euclidean\": f\"{euc_mpnet:.4f}\",\n",
    "    })\n",
    "\n",
    "df_extended = pd.DataFrame(results_extended)\n",
    "print(df_extended.to_string(index=False))\n",
    "# Euclidean = np.linalg.norm(a - b) is always >= 0 (verified in main table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Final Summary: Metric and Model Decisions\n",
    "\n",
    "### What Week 1 proved\n",
    "- Raw outputs were used in the main experiment (`normalize_embeddings=False`, no manual rescaling).\n",
    "- Norms are close to 1 for both models, which explains why dot and cosine are almost identical.\n",
    "- Euclidean stays non-negative when implemented as `np.linalg.norm(a-b)`.\n",
    "\n",
    "### Metric conclusion\n",
    "- **Champion metric:** cosine similarity (semantic direction, scale-invariant, interpretable).\n",
    "- For near-unit vectors, dot and cosine provide nearly the same ranking.\n",
    "- Under unit norms, `||a-b||^2 = 2 - 2(a·b)`, so Euclidean is monotonic with cosine/dot.\n",
    "\n",
    "### Model conclusion (Week 1)\n",
    "- **Week 1 selected model:** **MPNet** (better semantic separation in this comparison).\n",
    "\n",
    "### Handoff to Week 2\n",
    "Week 2 reuses MPNet as the embedding model and cosine as the champion metric.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}