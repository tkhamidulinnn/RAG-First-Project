{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1: Embeddings and Similarity Metrics\n",
    "\n",
    "**Scope:** Convert text to vector embeddings and compare using three similarity metrics.\n",
    "\n",
    "**Models:** `all-MiniLM-L6-v2` (384d), `all-mpnet-base-v2` (768d)\n",
    "\n",
    "**Metrics:** Dot Product, Cosine Similarity, Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: IMPORTS ONLY\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How SentenceTransformer Models Work\n",
    "\n",
    "### Architecture Overview\n",
    "\n",
    "**SentenceTransformer** models convert text into dense vector embeddings:\n",
    "\n",
    "1. **Tokenization**: Text → tokens (words/subwords)\n",
    "2. **Encoder**: Transformer (BERT/MPNet) processes tokens\n",
    "3. **Pooling**: Token embeddings → sentence embedding\n",
    "4. **Normalization**: L2-normalization (magnitude = 1.0)\n",
    "\n",
    "### Model Comparison\n",
    "\n",
    "| Model | Architecture | Dimensions | Speed | Quality |\n",
    "|-------|-------------|------------|-------|---------|\n",
    "| **all-MiniLM-L6-v2** | DistilBERT-based | 384 | Fast | Good |\n",
    "| **all-mpnet-base-v2** | MPNet | 768 | Slower | Better |\n",
    "\n",
    "### Why Normalization?\n",
    "\n",
    "- **L2-normalized embeddings** have magnitude = 1.0\n",
    "- Makes **dot product = cosine similarity** (faster computation)\n",
    "- Focuses on **direction** (semantic meaning) rather than magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: FUNCTIONS ONLY\n",
    "\n",
    "def dot_product(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    \"\"\"Dot product: sum of element-wise products.\"\"\"\n",
    "    return float(np.sum(a * b))\n",
    "\n",
    "\n",
    "def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    \"\"\"Cosine similarity: dot product normalized by vector magnitudes.\"\"\"\n",
    "    dot = np.sum(a * b)\n",
    "    norm_a = np.sqrt(np.sum(a * a))\n",
    "    norm_b = np.sqrt(np.sum(b * b))\n",
    "    return float(dot / (norm_a * norm_b))\n",
    "\n",
    "\n",
    "def euclidean_distance(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    \"\"\"Euclidean distance: L2 norm of difference vector.\"\"\"\n",
    "    diff = a - b\n",
    "    return float(np.sqrt(np.sum(diff * diff)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-by-Step Process\n",
    "\n",
    "Following the learning objectives:\n",
    "\n",
    "1. **Create an embedding of a string** - Convert text to vector representation\n",
    "2. **Compare with another string** - Compute similarity metrics between embeddings  \n",
    "3. **Use different model or different metric** - Compare MiniLM vs MPNet, try different metrics\n",
    "4. **And compare again** - Analyze results and understand differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Experiment 1: Load Models and Inspect Embedding Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 689.84it/s, Materializing param=pooler.dense.weight]                             \n",
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "Loading weights: 100%|██████████| 199/199 [00:00<00:00, 1532.14it/s, Materializing param=pooler.dense.weight]                        \n",
      "MPNetModel LOAD REPORT from: sentence-transformers/all-mpnet-base-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all-MiniLM-L6-v2 → shape: (384,), dimension: 384\n",
      "all-mpnet-base-v2 → shape: (768,), dimension: 768\n"
     ]
    }
   ],
   "source": [
    "# Load two SentenceTransformer models\n",
    "model_minilm = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "model_mpnet = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "# Inspect embedding dimensionality\n",
    "test_emb_minilm = model_minilm.encode(\"test\", convert_to_numpy=True)\n",
    "test_emb_mpnet = model_mpnet.encode(\"test\", convert_to_numpy=True)\n",
    "\n",
    "print(f\"all-MiniLM-L6-v2 → shape: {test_emb_minilm.shape}, dimension: {test_emb_minilm.shape[0]}\")\n",
    "print(f\"all-mpnet-base-v2 → shape: {test_emb_mpnet.shape}, dimension: {test_emb_mpnet.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Experiment 2: Define Test Sentences\n",
    "\n",
    "Five sentences with intentional semantic relationships:\n",
    "- **Similar:** sentences 0 and 1 (both about RAG)\n",
    "- **Dissimilar:** sentences 2 and 3 (unrelated topics)\n",
    "- **Ambiguous:** sentence 4 (partial overlap with sentence 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Retrieval Augmented Generation improves LLM accuracy.\n",
      "[1] RAG combines retrieval with language model generation.\n",
      "[2] The weather forecast predicts rain tomorrow.\n",
      "[3] Cooking pasta requires boiling water first.\n",
      "[4] Augmented generation uses external knowledge sources.\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"Retrieval Augmented Generation improves LLM accuracy.\",  \n",
    "    \"RAG combines retrieval with language model generation.\",  \n",
    "    \"The weather forecast predicts rain tomorrow.\",            \n",
    "    \"Cooking pasta requires boiling water first.\",             \n",
    "    \"Augmented generation uses external knowledge sources.\",   \n",
    "]\n",
    "\n",
    "for i, s in enumerate(sentences):\n",
    "    print(f\"[{i}] {s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Experiment 3: Generate and Inspect Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiniLM embeddings shape: (5, 384)\n",
      "MPNet embeddings shape: (5, 768)\n",
      "\n",
      "MiniLM sentence[0] first 20 values: [-0.0220228  -0.04396626  0.00447883  0.00055714 -0.03906972  0.02633511\n",
      " -0.03920497 -0.02817526 -0.0424859  -0.0353056   0.02738176  0.03074416\n",
      "  0.06076185 -0.0518314  -0.01392772  0.03338559  0.05736943  0.08991289\n",
      " -0.00394042 -0.07039431]\n",
      "MPNet sentence[0] first 20 values: [ 0.00166424  0.02360758 -0.01334266  0.0119692  -0.00710444 -0.0289734\n",
      "  0.00820648  0.00555653  0.00723216 -0.03528774 -0.02144891 -0.04206651\n",
      " -0.02553579 -0.02424748  0.04520509  0.01470743  0.0775855   0.0202875\n",
      " -0.02456869  0.01769613]\n",
      "\n",
      "MiniLM sentence[1] first 20 values: [-0.05334243  0.00511108  0.03446425  0.0302682  -0.06955914  0.10199971\n",
      " -0.0046838   0.02422921  0.02585307 -0.05582795  0.03232386 -0.02854197\n",
      "  0.09216493  0.01982816 -0.00994937  0.02559566  0.01926134  0.09612161\n",
      " -0.03321575 -0.08420756]\n",
      "MPNet sentence[1] first 20 values: [ 0.03124009  0.06057323 -0.00820602  0.01686119 -0.0040119  -0.00826977\n",
      " -0.01338058  0.00984433 -0.0417951  -0.03825008 -0.02362044 -0.05202848\n",
      " -0.03055206 -0.01627272  0.03378328 -0.02055146  0.05508814  0.00422976\n",
      " -0.03956488  0.00160704]\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for all sentences with both models\n",
    "embeddings_minilm = model_minilm.encode(sentences, convert_to_numpy=True)\n",
    "embeddings_mpnet = model_mpnet.encode(sentences, convert_to_numpy=True)\n",
    "\n",
    "print(f\"MiniLM embeddings shape: {embeddings_minilm.shape}\")\n",
    "print(f\"MPNet embeddings shape: {embeddings_mpnet.shape}\")\n",
    "\n",
    "# Inspect first embedding vector (first 10 values)\n",
    "print(f\"\\nMiniLM sentence[0] first 20 values: {embeddings_minilm[0][:20]}\")\n",
    "print(f\"MPNet sentence[0] first 20 values: {embeddings_mpnet[0][:20]}\")\n",
    "\n",
    "print(f\"\\nMiniLM sentence[1] first 20 values: {embeddings_minilm[1][:20]}\")\n",
    "print(f\"MPNet sentence[1] first 20 values: {embeddings_mpnet[1][:20]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MiniLM sentence[2] first 20 values: [-0.03793139 -0.0067027   0.13290353  0.08947232  0.02930467 -0.04770944\n",
      "  0.02003481  0.00341998 -0.03323781  0.03670828 -0.07299682 -0.05635128\n",
      " -0.01865374  0.02744901 -0.07360628 -0.01449102 -0.082166   -0.0573015\n",
      " -0.04159637 -0.00483347]\n",
      "MPNet sentence[2] first 20 values: [-0.02296168 -0.01276098 -0.02665962 -0.00522578  0.03129588 -0.04879913\n",
      " -0.00157662 -0.04130371  0.03052933  0.04309495 -0.02345158  0.00010839\n",
      " -0.01300488  0.03478848  0.0642921  -0.07581157  0.00876294 -0.02359559\n",
      " -0.02020937 -0.02968585]\n",
      "\n",
      "MiniLM sentence[3] first 20 values: [-0.05089941 -0.06859522 -0.03378077  0.07898146 -0.00367225 -0.04948081\n",
      "  0.00143986 -0.01937545 -0.02264489 -0.0874291  -0.03136565 -0.04872905\n",
      " -0.04889179  0.00374963 -0.00215146 -0.05085794  0.01486077 -0.01041566\n",
      "  0.01173994 -0.0577705 ]\n",
      "MPNet sentence[3] first 20 values: [-0.05005772 -0.02820258 -0.01830548 -0.01590468  0.02297864  0.04261016\n",
      "  0.02520946  0.03265034  0.08292221  0.03257069  0.00353434 -0.02040551\n",
      "  0.05408761 -0.00338053 -0.02185334  0.04097164  0.00769983  0.0397215\n",
      " -0.00223104 -0.00564872]\n",
      "\n",
      "MiniLM sentence[4] first 20 values: [-0.04578966 -0.04702238 -0.06140061  0.0596151   0.02561361  0.01096626\n",
      " -0.01821041 -0.01030466 -0.01299201  0.03676389  0.05425986  0.01812871\n",
      "  0.04107444 -0.05774542  0.07760706  0.06354985 -0.01400391 -0.04228547\n",
      "  0.0026783  -0.06058193]\n",
      "MPNet sentence[4] first 20 values: [ 0.00975559  0.03156675 -0.03285674 -0.01357452  0.04168465 -0.00732852\n",
      "  0.06677166 -0.00393427  0.00762493 -0.01992843  0.02744671  0.01870567\n",
      "  0.00671253 -0.01117941  0.0607666  -0.01301123  0.00514244  0.00605853\n",
      " -0.02351289  0.01655909]\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nMiniLM sentence[2] first 20 values: {embeddings_minilm[2][:20]}\")\n",
    "print(f\"MPNet sentence[2] first 20 values: {embeddings_mpnet[2][:20]}\")\n",
    "\n",
    "print(f\"\\nMiniLM sentence[3] first 20 values: {embeddings_minilm[3][:20]}\")\n",
    "print(f\"MPNet sentence[3] first 20 values: {embeddings_mpnet[3][:20]}\")\n",
    "\n",
    "print(f\"\\nMiniLM sentence[4] first 20 values: {embeddings_minilm[4][:20]}\")\n",
    "print(f\"MPNet sentence[4] first 20 values: {embeddings_mpnet[4][:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Experiment 4: Verify Embedding Normalization\n",
    "\n",
    "\n",
    "**What normalization means:**\n",
    "- **L2-normalization** scales each embedding vector so its magnitude (L2 norm) equals 1.0\n",
    "- Formula: `normalized_vector = vector / ||vector||` where `||vector|| = √(Σvᵢ²)`\n",
    "- This ensures all embeddings have the same \"length\" in vector space\n",
    "\n",
    "**Why it matters:**\n",
    "1. **Dot product = Cosine similarity**: When vectors are normalized, dot product equals cosine similarity because:\n",
    "   - `cosine = dot(a,b) / (||a|| × ||b||)`\n",
    "   - If `||a|| = ||b|| = 1`, then `cosine = dot(a,b)`\n",
    "   - This makes computation faster (no need to compute norms)\n",
    "\n",
    "2. **Focus on direction, not magnitude**: Normalized embeddings capture **semantic direction** rather than magnitude, which is what we want for semantic similarity\n",
    "\n",
    "3. **Efficient similarity search**: Normalized embeddings enable fast similarity search in vector databases using inner product\n",
    "\n",
    "**What we verify:**\n",
    "- Check that L2 norm of each embedding equals 1.0 (or very close to it)\n",
    "- Confirm this holds for all sentences and both models (MiniLM and MPNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 norms (should be ~1.0 if normalized):\n",
      "  Sentence 0: MiniLM=1.000000, MPNet=1.000000\n",
      "  Sentence 1: MiniLM=1.000000, MPNet=1.000000\n",
      "  Sentence 2: MiniLM=1.000000, MPNet=1.000000\n",
      "  Sentence 3: MiniLM=1.000000, MPNet=1.000000\n",
      "  Sentence 4: MiniLM=1.000000, MPNet=1.000000\n"
     ]
    }
   ],
   "source": [
    "# Check L2 norms of embeddings\n",
    "print(\"L2 norms (should be ~1.0 if normalized):\")\n",
    "for i in range(len(sentences)):\n",
    "    norm_minilm = np.sqrt(np.sum(embeddings_minilm[i] ** 2))\n",
    "    norm_mpnet = np.sqrt(np.sum(embeddings_mpnet[i] ** 2))\n",
    "    print(f\"  Sentence {i}: MiniLM={norm_minilm:.6f}, MPNet={norm_mpnet:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Experiment 5: Compute All Pairwise Similarities\n",
    "\n",
    "**Goal:** Compare select sentence pairs using all three similarity metrics (dot product, cosine similarity, euclidean distance) across both models.\n",
    "\n",
    "**What we do:**\n",
    "1. **Define pairs** of sentences with different semantic relationships:\n",
    "   - **Similar pairs** (0↔1): Both about RAG — should have high similarity\n",
    "   - **Ambiguous pairs** (0↔4, 1↔4): Partial semantic overlap — intermediate similarity expected\n",
    "   - **Dissimilar pairs** (0↔2, 2↔3): Unrelated topics — should have low similarity\n",
    "\n",
    "2. **Compute metrics** for each pair with both models:\n",
    "   - Dot product (normalized = cosine similarity)\n",
    "   - Cosine similarity (semantic direction)\n",
    "   - Euclidean distance (vector space distance)\n",
    "\n",
    "3. **Compare results** between MiniLM (384d) and MPNet (768d) to see how embedding dimensionality affects similarity scores.\n",
    "\n",
    "**Expected observations:**\n",
    "- Similar sentences should have high cosine (>0.5) and low euclidean distance (<1.0)\n",
    "- Dissimilar sentences should have low cosine (<0.3) and high euclidean distance (>1.2)\n",
    "- MPNet may show different similarity scores due to richer 768-dimensional representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       model_name                                  sentence_a                                  sentence_b  dot_similarity  cosine_similarity  euclidean_distance  embedding_dimension\n",
      " all-MiniLM-L6-v2 Retrieval Augmented Generation improves ... RAG combines retrieval with language mod...        0.480646           0.480646            1.019170                  384\n",
      " all-MiniLM-L6-v2 Retrieval Augmented Generation improves ... Augmented generation uses external knowl...        0.535589           0.535589            0.963754                  384\n",
      " all-MiniLM-L6-v2 Retrieval Augmented Generation improves ... The weather forecast predicts rain tomor...        0.048415           0.048415            1.379554                  384\n",
      " all-MiniLM-L6-v2 The weather forecast predicts rain tomor... Cooking pasta requires boiling water fir...        0.072848           0.072848            1.361729                  384\n",
      " all-MiniLM-L6-v2 RAG combines retrieval with language mod... Augmented generation uses external knowl...        0.263568           0.263568            1.213616                  384\n",
      "all-mpnet-base-v2 Retrieval Augmented Generation improves ... RAG combines retrieval with language mod...        0.607821           0.607821            0.885640                  768\n",
      "all-mpnet-base-v2 Retrieval Augmented Generation improves ... Augmented generation uses external knowl...        0.571282           0.571282            0.925979                  768\n",
      "all-mpnet-base-v2 Retrieval Augmented Generation improves ... The weather forecast predicts rain tomor...        0.030941           0.030941            1.392163                  768\n",
      "all-mpnet-base-v2 The weather forecast predicts rain tomor... Cooking pasta requires boiling water fir...        0.081372           0.081372            1.355454                  768\n",
      "all-mpnet-base-v2 RAG combines retrieval with language mod... Augmented generation uses external knowl...        0.363113           0.363113            1.128616                  768\n"
     ]
    }
   ],
   "source": [
    "# Define sentence pairs to compare\n",
    "pairs = [\n",
    "    (0, 1),  \n",
    "    (0, 4),  \n",
    "    (0, 2),  \n",
    "    (2, 3),  \n",
    "    (1, 4),  \n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_name, embeddings, dim in [\n",
    "    (\"all-MiniLM-L6-v2\", embeddings_minilm, 384),\n",
    "    (\"all-mpnet-base-v2\", embeddings_mpnet, 768),\n",
    "]:\n",
    "    for i, j in pairs:\n",
    "        emb_a = embeddings[i]\n",
    "        emb_b = embeddings[j]\n",
    "        \n",
    "        results.append({\n",
    "            \"model_name\": model_name,\n",
    "            \"sentence_a\": sentences[i][:40] + \"...\",\n",
    "            \"sentence_b\": sentences[j][:40] + \"...\",\n",
    "            \"dot_similarity\": dot_product(emb_a, emb_b),\n",
    "            \"cosine_similarity\": cosine_similarity(emb_a, emb_b),\n",
    "            \"euclidean_distance\": euclidean_distance(emb_a, emb_b),\n",
    "            \"embedding_dimension\": dim,\n",
    "        })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "print(df_results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Result Table (Primary Week 1 Artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>sentence_a</th>\n",
       "      <th>sentence_b</th>\n",
       "      <th>dot_similarity</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>euclidean_distance</th>\n",
       "      <th>embedding_dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>Retrieval Augmented Generation improves ...</td>\n",
       "      <td>RAG combines retrieval with language mod...</td>\n",
       "      <td>0.480646</td>\n",
       "      <td>0.480646</td>\n",
       "      <td>1.019170</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>Retrieval Augmented Generation improves ...</td>\n",
       "      <td>Augmented generation uses external knowl...</td>\n",
       "      <td>0.535589</td>\n",
       "      <td>0.535589</td>\n",
       "      <td>0.963754</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>Retrieval Augmented Generation improves ...</td>\n",
       "      <td>The weather forecast predicts rain tomor...</td>\n",
       "      <td>0.048415</td>\n",
       "      <td>0.048415</td>\n",
       "      <td>1.379554</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>The weather forecast predicts rain tomor...</td>\n",
       "      <td>Cooking pasta requires boiling water fir...</td>\n",
       "      <td>0.072848</td>\n",
       "      <td>0.072848</td>\n",
       "      <td>1.361729</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>RAG combines retrieval with language mod...</td>\n",
       "      <td>Augmented generation uses external knowl...</td>\n",
       "      <td>0.263568</td>\n",
       "      <td>0.263568</td>\n",
       "      <td>1.213616</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>Retrieval Augmented Generation improves ...</td>\n",
       "      <td>RAG combines retrieval with language mod...</td>\n",
       "      <td>0.607821</td>\n",
       "      <td>0.607821</td>\n",
       "      <td>0.885640</td>\n",
       "      <td>768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>Retrieval Augmented Generation improves ...</td>\n",
       "      <td>Augmented generation uses external knowl...</td>\n",
       "      <td>0.571282</td>\n",
       "      <td>0.571282</td>\n",
       "      <td>0.925979</td>\n",
       "      <td>768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>Retrieval Augmented Generation improves ...</td>\n",
       "      <td>The weather forecast predicts rain tomor...</td>\n",
       "      <td>0.030941</td>\n",
       "      <td>0.030941</td>\n",
       "      <td>1.392163</td>\n",
       "      <td>768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>The weather forecast predicts rain tomor...</td>\n",
       "      <td>Cooking pasta requires boiling water fir...</td>\n",
       "      <td>0.081372</td>\n",
       "      <td>0.081372</td>\n",
       "      <td>1.355454</td>\n",
       "      <td>768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>RAG combines retrieval with language mod...</td>\n",
       "      <td>Augmented generation uses external knowl...</td>\n",
       "      <td>0.363113</td>\n",
       "      <td>0.363113</td>\n",
       "      <td>1.128616</td>\n",
       "      <td>768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model_name                                   sentence_a  \\\n",
       "0   all-MiniLM-L6-v2  Retrieval Augmented Generation improves ...   \n",
       "1   all-MiniLM-L6-v2  Retrieval Augmented Generation improves ...   \n",
       "2   all-MiniLM-L6-v2  Retrieval Augmented Generation improves ...   \n",
       "3   all-MiniLM-L6-v2  The weather forecast predicts rain tomor...   \n",
       "4   all-MiniLM-L6-v2  RAG combines retrieval with language mod...   \n",
       "5  all-mpnet-base-v2  Retrieval Augmented Generation improves ...   \n",
       "6  all-mpnet-base-v2  Retrieval Augmented Generation improves ...   \n",
       "7  all-mpnet-base-v2  Retrieval Augmented Generation improves ...   \n",
       "8  all-mpnet-base-v2  The weather forecast predicts rain tomor...   \n",
       "9  all-mpnet-base-v2  RAG combines retrieval with language mod...   \n",
       "\n",
       "                                    sentence_b  dot_similarity  \\\n",
       "0  RAG combines retrieval with language mod...        0.480646   \n",
       "1  Augmented generation uses external knowl...        0.535589   \n",
       "2  The weather forecast predicts rain tomor...        0.048415   \n",
       "3  Cooking pasta requires boiling water fir...        0.072848   \n",
       "4  Augmented generation uses external knowl...        0.263568   \n",
       "5  RAG combines retrieval with language mod...        0.607821   \n",
       "6  Augmented generation uses external knowl...        0.571282   \n",
       "7  The weather forecast predicts rain tomor...        0.030941   \n",
       "8  Cooking pasta requires boiling water fir...        0.081372   \n",
       "9  Augmented generation uses external knowl...        0.363113   \n",
       "\n",
       "   cosine_similarity  euclidean_distance  embedding_dimension  \n",
       "0           0.480646            1.019170                  384  \n",
       "1           0.535589            0.963754                  384  \n",
       "2           0.048415            1.379554                  384  \n",
       "3           0.072848            1.361729                  384  \n",
       "4           0.263568            1.213616                  384  \n",
       "5           0.607821            0.885640                  768  \n",
       "6           0.571282            0.925979                  768  \n",
       "7           0.030941            1.392163                  768  \n",
       "8           0.081372            1.355454                  768  \n",
       "9           0.363113            1.128616                  768  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Experiment 6: Demonstrate Metric Behavior Differences\n",
    "\n",
    "**Goal:** Show that dot product ≠ cosine similarity when vectors are NOT normalized, and understand why normalization matters.\n",
    "\n",
    "**What we do:**\n",
    "1. **Start with normalized vectors**: Take two embeddings that are already L2-normalized (from Experiment 3)\n",
    "   - Both have norm = 1.0\n",
    "   - Dot product = cosine similarity (as verified in Experiment 4)\n",
    "\n",
    "2. **Artificially scale one vector**: Multiply one embedding by 3.0\n",
    "   - This makes it NOT normalized (norm = 3.0)\n",
    "   - Creates a scenario where vectors have different magnitudes\n",
    "\n",
    "3. **Compare metrics**: Compute both dot product and cosine similarity\n",
    "   - With normalized vectors: dot = cosine\n",
    "   - With scaled vector: dot ≠ cosine\n",
    "\n",
    "**Why this matters:**\n",
    "- **Dot product** depends on BOTH direction AND magnitude\n",
    "- **Cosine similarity** depends ONLY on direction (normalizes by magnitudes)\n",
    "- When vectors are normalized, they have the same magnitude, so dot = cosine\n",
    "- When vectors have different magnitudes, dot product changes but cosine stays the same\n",
    "\n",
    "**Expected results:**\n",
    "- Normalized vectors: dot product ≈ cosine similarity (same value)\n",
    "- Scaled vector: dot product changes (multiplied by ~3), cosine similarity unchanged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing sentence 0 vs sentence 1 (MiniLM):\n",
      "  emb_b norm (original): 1.0000\n",
      "  emb_b_scaled norm:     3.0000\n",
      "\n",
      "With normalized vectors:\n",
      "  Dot Product:       0.480646\n",
      "  Cosine Similarity: 0.480646\n",
      "\n",
      "With scaled vector (emb_b × 3):\n",
      "  Dot Product:       1.441938  ← changes with magnitude\n",
      "  Cosine Similarity: 0.480646  ← unchanged (direction only)\n"
     ]
    }
   ],
   "source": [
    "# Take two embeddings and artificially scale one\n",
    "emb_a = embeddings_minilm[0].copy()  # normalized\n",
    "emb_b = embeddings_minilm[1].copy()  # normalized\n",
    "emb_b_scaled = emb_b * 3.0           # NOT normalized (magnitude = 3)\n",
    "\n",
    "print(\"Comparing sentence 0 vs sentence 1 (MiniLM):\")\n",
    "print(f\"  emb_b norm (original): {np.sqrt(np.sum(emb_b ** 2)):.4f}\")\n",
    "print(f\"  emb_b_scaled norm:     {np.sqrt(np.sum(emb_b_scaled ** 2)):.4f}\")\n",
    "print()\n",
    "print(\"With normalized vectors:\")\n",
    "print(f\"  Dot Product:       {dot_product(emb_a, emb_b):.6f}\")\n",
    "print(f\"  Cosine Similarity: {cosine_similarity(emb_a, emb_b):.6f}\")\n",
    "print()\n",
    "print(\"With scaled vector (emb_b × 3):\")\n",
    "print(f\"  Dot Product:       {dot_product(emb_a, emb_b_scaled):.6f}  ← changes with magnitude\")\n",
    "print(f\"  Cosine Similarity: {cosine_similarity(emb_a, emb_b_scaled):.6f}  ← unchanged (direction only)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Experiment 7 : Compare Different Embedding Pairs with Different Metrics\n",
    "\n",
    "Compare multiple sentence pairs (similar, dissimilar, ambiguous) using both cosine and euclidean metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPARISON: Different Embedding Pairs × Metrics × Models\n",
      "Pair       Type                 Description MiniLM Cosine MiniLM Euclidean MPNet Cosine MPNet Euclidean\n",
      " 0↔1    Similar              Both about RAG        0.4806          -1.0192       0.6078         -0.8856\n",
      " 0↔2 Dissimilar              RAG vs Weather        0.0484          -1.3796       0.0309         -1.3922\n",
      " 0↔4  Ambiguous RAG vs Augmented generation        0.5356          -0.9638       0.5713         -0.9260\n",
      " 2↔3 Dissimilar          Weather vs Cooking        0.0728          -1.3617       0.0814         -1.3555\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"COMPARISON: Different Embedding Pairs × Metrics × Models\")\n",
    "\n",
    "\n",
    "pairs_info = [\n",
    "    (0, 1, \"Similar\", \"Both about RAG\"),\n",
    "    (0, 2, \"Dissimilar\", \"RAG vs Weather\"),\n",
    "    (0, 4, \"Ambiguous\", \"RAG vs Augmented generation\"),\n",
    "    (2, 3, \"Dissimilar\", \"Weather vs Cooking\"),\n",
    "]\n",
    "\n",
    "model_minilm.similarity_fn_name = \"cosine\"\n",
    "model_mpnet.similarity_fn_name = \"cosine\"\n",
    "\n",
    "results_extended = []\n",
    "\n",
    "for i, j, pair_type, description in pairs_info:\n",
    "    emb_i_minilm = embeddings_minilm[i]\n",
    "    emb_j_minilm = embeddings_minilm[j]\n",
    "    emb_i_mpnet = embeddings_mpnet[i]\n",
    "    emb_j_mpnet = embeddings_mpnet[j]\n",
    "    \n",
    "    # Cosine similarity (default)\n",
    "    cos_minilm = model_minilm.similarity(emb_i_minilm, emb_j_minilm).item()\n",
    "    cos_mpnet = model_mpnet.similarity(emb_i_mpnet, emb_j_mpnet).item()\n",
    "    \n",
    "    # Change to euclidean\n",
    "    model_minilm.similarity_fn_name = \"euclidean\"\n",
    "    model_mpnet.similarity_fn_name = \"euclidean\"\n",
    "    \n",
    "    euc_minilm = model_minilm.similarity(emb_i_minilm, emb_j_minilm).item()\n",
    "    euc_mpnet = model_mpnet.similarity(emb_i_mpnet, emb_j_mpnet).item()\n",
    "    \n",
    "    # Reset back to cosine for next iteration\n",
    "    model_minilm.similarity_fn_name = \"cosine\"\n",
    "    model_mpnet.similarity_fn_name = \"cosine\"\n",
    "    \n",
    "    results_extended.append({\n",
    "        \"Pair\": f\"{i}↔{j}\",\n",
    "        \"Type\": pair_type,\n",
    "        \"Description\": description,\n",
    "        \"MiniLM Cosine\": f\"{cos_minilm:.4f}\",\n",
    "        \"MiniLM Euclidean\": f\"{euc_minilm:.4f}\",\n",
    "        \"MPNet Cosine\": f\"{cos_mpnet:.4f}\",\n",
    "        \"MPNet Euclidean\": f\"{euc_mpnet:.4f}\",\n",
    "    })\n",
    "\n",
    "df_extended = pd.DataFrame(results_extended)\n",
    "print(df_extended.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Final Summary: All Similarity Metrics Comparison\n",
    "\n",
    "### Overview of All Three Metrics\n",
    "\n",
    "| Metric | Range | Interpretation | When Dot = Cosine? |\n",
    "|--------|-------|----------------|-------------------|\n",
    "| **Dot Product** | (−∞, +∞) | Unbounded; depends on vector magnitudes | ✅ When vectors are L2-normalized |\n",
    "| **Cosine Similarity** | [−1, +1] | 1 = identical direction, 0 = orthogonal, −1 = opposite | ✅ Always (by definition) |\n",
    "| **Euclidean Distance** | [0, +∞) | 0 = identical vectors, larger = more dissimilar | ❌ Never (different concept) |\n",
    "\n",
    "### Key Findings Across All Experiments\n",
    "\n",
    "#### 1. Normalization Matters (Experiment 4)\n",
    "- ✅ All embeddings are L2-normalized (norm = 1.0)\n",
    "- ✅ This makes **dot product = cosine similarity** (faster computation)\n",
    "- ✅ Normalization focuses on **direction** (semantic meaning) rather than magnitude\n",
    "\n",
    "#### 2. Metric Behavior (Experiment 5 & 6)\n",
    "- **Dot Product**: \n",
    "  - With normalized vectors: dot = cosine (same value)\n",
    "  - With non-normalized vectors: dot ≠ cosine (depends on magnitude)\n",
    "- **Cosine Similarity**: \n",
    "  - Always measures direction only (angle between vectors)\n",
    "  - Unchanged by vector scaling (Experiment 6)\n",
    "- **Euclidean Distance**: \n",
    "  - Measures actual distance in vector space\n",
    "  - Inverse to similarity (smaller = more similar)\n",
    "  - For normalized vectors: `euclidean = √(2 - 2×cosine)`\n",
    "\n",
    "#### 3. Model Comparison (All Experiments)\n",
    "- **MiniLM (384d)**: Faster, good quality\n",
    "- **MPNet (768d)**: Slower, better quality, richer representation\n",
    "- Both models show similar trends but different absolute values\n",
    "\n",
    "#### 4. Pair Type Analysis (Experiment 5 & 7 Extended)\n",
    "- **Similar pairs** (0↔1): \n",
    "  - Cosine: >0.4 (high similarity)\n",
    "  - Euclidean: <1.1 (low distance)\n",
    "- **Dissimilar pairs** (0↔2, 2↔3): \n",
    "  - Cosine: <0.1 (low similarity)\n",
    "  - Euclidean: >1.3 (high distance)\n",
    "- **Ambiguous pairs** (0↔4): \n",
    "  - Cosine: 0.1-0.4 (intermediate)\n",
    "  - Euclidean: 1.1-1.3 (intermediate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
